# @package _global_

# to execute this experiment run:
# python run.py experiment=vision_baseline_on_emoreccom.yaml

defaults:
  - override /trainer: default.yaml
  - override /model: vision_baseline_model.yaml
  - override /datamodule: emoreccom_bb_datamodule.yaml
  - override /callbacks: default.yaml
  - override /logger: tensorboard.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 12345

model:
  num_emotion_classes: 8
  num_cont_classes: -1
  pretrained_model_path: "/Users/caghankoksal/Documents/emotion-recognition-drawings/pretrained_weights"
  cat_loss_param: 0.5
  arch: "resnet18"
  model_context_num_classes: 365
  lr: 0.001
  weight_decay: 0.0005
  scheduler_step_size: 7
  scheduler_gamma: 0.1
  discrete_loss: True
  continuous_loss: False

datamodule:
  data_dir: "/Users/caghankoksal/Documents/emotion-recognition-drawings/emorec"
  modality: 3
  batch_size: 32
  train_val_test_split: [ 5112, 500, 500 ]
  num_workers: 0
  pin_memory: False
  use_tokenizer_instead_text_preprocessor: True
  tokenizer_name: squeezebert/squeezebert-uncased
  tokenizer_max_len: 80




  
trainer:
  gpus: 1
  min_epochs: 1
  max_epochs: 20
  gradient_clip_val: 0.5
  

callbacks:
  model_checkpoint:
    monitor: "val/micro_auc"
  early_stopping:
    monitor: "val/micro_auc"

